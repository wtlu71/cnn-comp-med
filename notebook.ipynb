{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "0b867135",
      "metadata": {
        "id": "0b867135"
      },
      "source": [
        "# Notebook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "7837677e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7837677e",
        "outputId": "dfc3149a-d02c-4987-8ab1-9e639e423b6b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'cnn-comp-med'...\n",
            "remote: Enumerating objects: 76, done.\u001b[K\n",
            "remote: Counting objects: 100% (76/76), done.\u001b[K\n",
            "remote: Compressing objects: 100% (64/64), done.\u001b[K\n",
            "remote: Total 76 (delta 35), reused 30 (delta 8), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (76/76), 38.58 KiB | 12.86 MiB/s, done.\n",
            "Resolving deltas: 100% (35/35), done.\n"
          ]
        }
      ],
      "source": [
        "# installs- comment out if good\n",
        "\n",
        "!git clone https://github.com/wtlu71/cnn-comp-med.git\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import sys\n",
        "import os\n",
        "\n",
        "repo_path = '/content/cnn-comp-med'\n",
        "# Add to Python path\n",
        "sys.path.append(repo_path)\n",
        "# imports\n",
        "from my_scripts.test import potato\n",
        "from my_scripts.my_models import SmallCNN, SmallMLP\n",
        "from my_scripts.dataset_loading import H5Dataset\n",
        "from my_scripts.utils import run_epoch\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset,DataLoader, Subset\n",
        "import torchvision.models as models\n",
        "from torchvision.models import resnet50\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "device = 'mps' if torch.backends.mps.is_available() else 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "# Path to your repo in Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "89bdd56f",
      "metadata": {
        "id": "89bdd56f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76fe8b75-5e8d-4441-9f17-9d367014391a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6\n"
          ]
        }
      ],
      "source": [
        "print(potato(2, 4))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9d56a87d",
      "metadata": {
        "id": "9d56a87d"
      },
      "source": [
        "Get train/val/test data from Zenodo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "3870334d",
      "metadata": {
        "id": "3870334d"
      },
      "outputs": [],
      "source": [
        "os.makedirs(os.path.join(os.getcwd(),\"data\"),exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "ec4ba219",
      "metadata": {
        "id": "ec4ba219",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "352243f3-9053-4e33-c278-4ec34f6c86d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libaria2-0 libc-ares2\n",
            "The following NEW packages will be installed:\n",
            "  aria2 libaria2-0 libc-ares2\n",
            "0 upgraded, 3 newly installed, 0 to remove and 41 not upgraded.\n",
            "Need to get 1,513 kB of archives.\n",
            "After this operation, 5,441 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libc-ares2 amd64 1.18.1-1ubuntu0.22.04.3 [45.1 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libaria2-0 amd64 1.36.0-1 [1,086 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 aria2 amd64 1.36.0-1 [381 kB]\n",
            "Fetched 1,513 kB in 2s (980 kB/s)\n",
            "Selecting previously unselected package libc-ares2:amd64.\n",
            "(Reading database ... 121713 files and directories currently installed.)\n",
            "Preparing to unpack .../libc-ares2_1.18.1-1ubuntu0.22.04.3_amd64.deb ...\n",
            "Unpacking libc-ares2:amd64 (1.18.1-1ubuntu0.22.04.3) ...\n",
            "Selecting previously unselected package libaria2-0:amd64.\n",
            "Preparing to unpack .../libaria2-0_1.36.0-1_amd64.deb ...\n",
            "Unpacking libaria2-0:amd64 (1.36.0-1) ...\n",
            "Selecting previously unselected package aria2.\n",
            "Preparing to unpack .../aria2_1.36.0-1_amd64.deb ...\n",
            "Unpacking aria2 (1.36.0-1) ...\n",
            "Setting up libc-ares2:amd64 (1.18.1-1ubuntu0.22.04.3) ...\n",
            "Setting up libaria2-0:amd64 (1.36.0-1) ...\n",
            "Setting up aria2 (1.36.0-1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero_v2.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "\n",
            "11/27 05:34:43 [\u001b[1;32mNOTICE\u001b[0m] Downloading 1 item(s)\n",
            " *** Download Progress Summary as of Thu Nov 27 05:35:44 2025 *** \n",
            "=\n",
            "[#15a2de 1.1GiB/5.9GiB(20%) CN:16 DL:15MiB ETA:5m26s]\n",
            "FILE: /content/data/train_x.h5.gz\n",
            "-\n",
            "\n",
            " *** Download Progress Summary as of Thu Nov 27 05:36:44 2025 *** \n",
            "=\n",
            "[#15a2de 2.1GiB/5.9GiB(35%) CN:16 DL:15MiB ETA:4m11s]\n",
            "FILE: /content/data/train_x.h5.gz\n",
            "-\n",
            "\n",
            " *** Download Progress Summary as of Thu Nov 27 05:37:45 2025 *** \n",
            "=\n",
            "[#15a2de 3.0GiB/5.9GiB(50%) CN:16 DL:15MiB ETA:3m14s]\n",
            "FILE: /content/data/train_x.h5.gz\n",
            "-\n",
            "\n",
            " *** Download Progress Summary as of Thu Nov 27 05:38:46 2025 *** \n",
            "=\n",
            "[#15a2de 3.9GiB/5.9GiB(66%) CN:16 DL:15MiB ETA:2m11s]\n",
            "FILE: /content/data/train_x.h5.gz\n",
            "-\n",
            "\n",
            " *** Download Progress Summary as of Thu Nov 27 05:39:47 2025 *** \n",
            "=\n",
            "[#15a2de 4.8GiB/5.9GiB(81%) CN:16 DL:15MiB ETA:1m11s]\n",
            "FILE: /content/data/train_x.h5.gz\n",
            "-\n",
            "\n",
            "\u001b[0m\n",
            "11/27 05:40:35 [\u001b[1;32mNOTICE\u001b[0m] Download complete: /content/data/train_x.h5.gz\n",
            "\n",
            "Download Results:\n",
            "gid   |stat|avg speed  |path/URI\n",
            "======+====+===========+=======================================================\n",
            "15a2de|\u001b[1;32mOK\u001b[0m  |    17MiB/s|/content/data/train_x.h5.gz\n",
            "\n",
            "Status Legend:\n",
            "(OK):download completed.\n",
            "--2025-11-27 05:42:13--  https://zenodo.org/records/2546921/files/camelyonpatch_level_2_split_train_y.h5.gz?download=1\n",
            "Resolving zenodo.org (zenodo.org)... 137.138.52.235, 188.185.48.75, 188.185.43.153, ...\n",
            "Connecting to zenodo.org (zenodo.org)|137.138.52.235|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 21378 (21K) [application/octet-stream]\n",
            "Saving to: ‘data/train_y.h5.gz’\n",
            "\n",
            "data/train_y.h5.gz  100%[===================>]  20.88K   129KB/s    in 0.2s    \n",
            "\n",
            "2025-11-27 05:42:14 (129 KB/s) - ‘data/train_y.h5.gz’ saved [21378/21378]\n",
            "\n",
            "\n",
            "11/27 05:42:14 [\u001b[1;32mNOTICE\u001b[0m] Downloading 1 item(s)\n",
            "\u001b[0m\n",
            "11/27 05:43:14 [\u001b[1;32mNOTICE\u001b[0m] Download complete: /content/data/valid_x.h5.gz\n",
            "\n",
            "Download Results:\n",
            "gid   |stat|avg speed  |path/URI\n",
            "======+====+===========+=======================================================\n",
            "2b2021|\u001b[1;32mOK\u001b[0m  |    13MiB/s|/content/data/valid_x.h5.gz\n",
            "\n",
            "Status Legend:\n",
            "(OK):download completed.\n",
            "--2025-11-27 05:43:23--  https://zenodo.org/records/2546921/files/camelyonpatch_level_2_split_valid_y.h5.gz?download=1\n",
            "Resolving zenodo.org (zenodo.org)... 137.138.52.235, 188.185.43.153, 188.185.48.75, ...\n",
            "Connecting to zenodo.org (zenodo.org)|137.138.52.235|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3038 (3.0K) [application/octet-stream]\n",
            "Saving to: ‘data/valid_y.h5.gz’\n",
            "\n",
            "data/valid_y.h5.gz  100%[===================>]   2.97K  --.-KB/s    in 0.006s  \n",
            "\n",
            "2025-11-27 05:43:24 (467 KB/s) - ‘data/valid_y.h5.gz’ saved [3038/3038]\n",
            "\n",
            "\n",
            "11/27 05:43:24 [\u001b[1;32mNOTICE\u001b[0m] Downloading 1 item(s)\n",
            "\u001b[0m\n",
            "11/27 05:44:19 [\u001b[1;32mNOTICE\u001b[0m] Download complete: /content/data/test_x.h5.gz\n",
            "\n",
            "Download Results:\n",
            "gid   |stat|avg speed  |path/URI\n",
            "======+====+===========+=======================================================\n",
            "4a5fa9|\u001b[1;32mOK\u001b[0m  |    14MiB/s|/content/data/test_x.h5.gz\n",
            "\n",
            "Status Legend:\n",
            "(OK):download completed.\n",
            "--2025-11-27 05:44:31--  https://zenodo.org/records/2546921/files/camelyonpatch_level_2_split_test_y.h5.gz?download=1\n",
            "Resolving zenodo.org (zenodo.org)... 188.185.43.153, 188.185.48.75, 137.138.52.235, ...\n",
            "Connecting to zenodo.org (zenodo.org)|188.185.43.153|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3040 (3.0K) [application/octet-stream]\n",
            "Saving to: ‘data/test_y.h5.gz’\n",
            "\n",
            "data/test_y.h5.gz   100%[===================>]   2.97K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2025-11-27 05:44:31 (199 KB/s) - ‘data/test_y.h5.gz’ saved [3040/3040]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# !apt-get install -y wget2\n",
        "!apt-get install -y aria2\n",
        "\n",
        "# !aria2c -x 16 -s 16 -k 1M -c -j 1 \"URL\" -o output_filename\n",
        "#train\n",
        "!aria2c -x 16 -s 16 -k 1M -c -j 1 \"https://zenodo.org/records/2546921/files/camelyonpatch_level_2_split_train_x.h5.gz?download=1\" -o data/train_x.h5.gz\n",
        "!gunzip data/train_x.h5.gz\n",
        "\n",
        "!wget https://zenodo.org/records/2546921/files/camelyonpatch_level_2_split_train_y.h5.gz?download=1 -O data/train_y.h5.gz\n",
        "!gunzip data/train_y.h5.gz\n",
        "\n",
        "# val\n",
        "!aria2c -x 16 -s 16 -k 1M -c -j 1 \"https://zenodo.org/records/2546921/files/camelyonpatch_level_2_split_valid_x.h5.gz?download=1\" -o data/valid_x.h5.gz\n",
        "!gunzip data/valid_x.h5.gz\n",
        "\n",
        "!wget https://zenodo.org/records/2546921/files/camelyonpatch_level_2_split_valid_y.h5.gz?download=1 -O data/valid_y.h5.gz\n",
        "!gunzip data/valid_y.h5.gz\n",
        "\n",
        "# test\n",
        "!aria2c -x 16 -s 16 -k 1M -c -j 1 \"https://zenodo.org/records/2546921/files/camelyonpatch_level_2_split_test_x.h5.gz?download=1\" -o data/test_x.h5.gz\n",
        "!gunzip data/test_x.h5.gz\n",
        "\n",
        "!wget https://zenodo.org/records/2546921/files/camelyonpatch_level_2_split_test_y.h5.gz?download=1 -O data/test_y.h5.gz\n",
        "!gunzip data/test_y.h5.gz\n",
        "\n",
        "# # train\n",
        "# !wget2 --progress=bar:force https://zenodo.org/records/2546921/files/camelyonpatch_level_2_split_train_x.h5.gz?download=1 -O data/train_x.h5.gz\n",
        "# !gunzip data/train_x.h5.gz\n",
        "\n",
        "# !wget2 --progress=bar:force https://zenodo.org/records/2546921/files/camelyonpatch_level_2_split_train_y.h5.gz?download=1 -O data/train_y.h5.gz\n",
        "# !gunzip data/train_y.h5.gz\n",
        "\n",
        "# # val\n",
        "# !wget2 --progress=bar:force https://zenodo.org/records/2546921/files/camelyonpatch_level_2_split_valid_x.h5.gz?download=1 -O data/valid_x.h5.gz\n",
        "# !gunzip data/valid_x.h5.gz\n",
        "\n",
        "# !wget2 --progress=bar:force https://zenodo.org/records/2546921/files/camelyonpatch_level_2_split_valid_y.h5.gz?download=1 -O data/valid_y.h5.gz\n",
        "# !gunzip data/valid_y.h5.gz\n",
        "\n",
        "# # test\n",
        "# !wget2 --progress=bar:force https://zenodo.org/records/2546921/files/camelyonpatch_level_2_split_test_x.h5.gz?download=1 -O data/test_x.h5.gz\n",
        "# !gunzip data/test_x.h5.gz\n",
        "\n",
        "# !wget2 --progress=bar:force https://zenodo.org/records/2546921/files/camelyonpatch_level_2_split_test_y.h5.gz?download=1 -O data/test_y.h5.gz\n",
        "# !gunzip data/test_y.h5.gz"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "577122da",
      "metadata": {
        "id": "577122da"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "130649a2",
      "metadata": {
        "id": "130649a2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3dbeac09-3743-4b1c-913f-4745de03beb8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data transforms defined\n"
          ]
        }
      ],
      "source": [
        "# define transforms\n",
        "\n",
        "# is there a way to get this programmatically from the data or not worth it\n",
        "IMG_SIZE = 96\n",
        "BATCH_SIZE = 3\n",
        "\n",
        "# Training transforms with augmentation\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomVerticalFlip(),\n",
        "    #transforms.RandomRotation(10),\n",
        "    # TODO: normalize: mean and std for ImageNet (mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    #transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Validation/Test transforms (no augmentation)\n",
        "eval_transforms = transforms.Compose([\n",
        "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "    # TODO: normalize: mean and std for ImageNet (mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    #transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "print(\"Data transforms defined\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "2a869510",
      "metadata": {
        "id": "2a869510",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0cce2a97-ada0-4317-a9e4-af3a2323edeb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using GPU\n"
          ]
        }
      ],
      "source": [
        "# dataset paths- Colab virtual session\n",
        "train_img_h5_path = \"data/train_x.h5\"\n",
        "train_label_h5_path = \"data/train_y.h5\"\n",
        "\n",
        "val_img_h5_path = \"data/valid_x.h5\"\n",
        "val_label_h5_path = \"data/valid_y.h5\"\n",
        "\n",
        "test_img_h5_path = \"data/test_x.h5\"\n",
        "test_label_h5_path = \"data/test_y.h5\"\n",
        "\n",
        "train_subset_size = 50\n",
        "eval_subset_size = 10\n",
        "\n",
        "train_dataset = H5Dataset(train_img_h5_path,train_label_h5_path,transform=train_transforms)\n",
        "# train_dataset_subset = Subset(train_dataset, range(train_subset_size))\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
        "\n",
        "val_dataset = H5Dataset(val_img_h5_path,val_label_h5_path,transform=train_transforms)\n",
        "# val_dataset_subset = Subset(val_dataset, range(eval_subset_size))\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
        "\n",
        "test_dataset = H5Dataset(test_img_h5_path,test_label_h5_path,transform=train_transforms)\n",
        "# test_dataset_subset = Subset(test_dataset, range(eval_subset_size))\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(\"Using GPU\")\n",
        "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=True)\n",
        "else:\n",
        "    print(\"Using CPU\")\n",
        "    # train_dataset_subset = Subset(train_dataset, range(train_subset_size))\n",
        "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
        "    # val_dataset_subset = Subset(val_dataset, range(eval_subset_size))\n",
        "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
        "    # test_dataset_subset = Subset(test_dataset, range(eval_subset_size))\n",
        "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "ea2f0bdd",
      "metadata": {
        "id": "ea2f0bdd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97b389da-9749-4468-fe08-e934d03069a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 97.8M/97.8M [00:00<00:00, 179MB/s]\n"
          ]
        }
      ],
      "source": [
        "# define/load models\n",
        "mlpmodel = SmallMLP().to(device)\n",
        "smallcnnmodel = SmallCNN().to(device)\n",
        "resnetmodel = resnet50(weights = models.ResNet50_Weights.IMAGENET1K_V2).to(device)\n",
        "\n",
        "# training hyperparameters\n",
        "# can change learning rate or use scheduler\n",
        "LEARNING_RATE = 3e-4\n",
        "# finetune with less epochs to avoid forgetting\n",
        "EPOCHS = 10\n",
        "PATIENCE = 5\n",
        "# patience- number of epochs the model continues after no improvement in validation loss\n",
        "\n",
        "# consider other loss functions https://neptune.ai/blog/pytorch-loss-functions\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# don't change adam, never change dude\n",
        "# optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1fd1d2e",
      "metadata": {
        "id": "c1fd1d2e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "867cf71a-8af5-4a3c-ad47-7dea67bda20c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training SmallMLP...\n",
            "\n",
            "Starting training...\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|█         | 1/10 [09:26<1:24:54, 566.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 01: train_loss=0.7051 val_loss=0.7053 val_acc=0.500 val_auc=0.500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 2/10 [17:55<1:11:02, 532.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 02: train_loss=0.6999 val_loss=0.6936 val_acc=0.500 val_auc=0.500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 3/10 [26:25<1:00:57, 522.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 03: train_loss=0.6991 val_loss=0.7084 val_acc=0.500 val_auc=0.500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 4/10 [35:03<52:04, 520.76s/it]  "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 04: train_loss=0.7027 val_loss=0.6969 val_acc=0.500 val_auc=0.500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 5/10 [43:46<43:26, 521.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 05: train_loss=0.6987 val_loss=0.6941 val_acc=0.500 val_auc=0.500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 5/10 [52:22<52:22, 628.53s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 06: train_loss=0.7001 val_loss=0.6988 val_acc=0.500 val_auc=0.500\n",
            "\n",
            "Early stopping at epoch 6\n",
            "\n",
            "Restored best model (val_auc=0.5000)\n",
            "Training SmallCNN...\n",
            "\n",
            "Starting training...\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|█         | 1/10 [10:40<1:36:00, 640.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 01: train_loss=0.4808 val_loss=0.5864 val_acc=0.670 val_auc=0.872\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 2/10 [21:22<1:25:30, 641.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 02: train_loss=0.4354 val_loss=0.4995 val_acc=0.729 val_auc=0.884\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 3/10 [32:01<1:14:41, 640.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 03: train_loss=0.4269 val_loss=0.4614 val_acc=0.765 val_auc=0.896\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 4/10 [42:39<1:03:57, 639.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 04: train_loss=0.4212 val_loss=0.4557 val_acc=0.793 val_auc=0.893\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 5/10 [53:12<53:06, 637.27s/it]  "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 05: train_loss=0.4200 val_loss=0.4400 val_acc=0.820 val_auc=0.903\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 6/10 [1:03:42<42:19, 634.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 06: train_loss=0.4208 val_loss=0.4256 val_acc=0.800 val_auc=0.910\n"
          ]
        }
      ],
      "source": [
        "modellist = [mlpmodel, smallcnnmodel, resnetmodel]\n",
        "modeldict = {\n",
        "    \"SmallMLP\": mlpmodel,\n",
        "    \"SmallCNN\": smallcnnmodel,\n",
        "    \"ResNet\": resnetmodel\n",
        "}\n",
        "# modellist = [mlpmodel, smallcnnmodel]\n",
        "\n",
        "historylist = []\n",
        "stopepochs = []\n",
        "\n",
        "for modelname, model in modeldict.items():\n",
        "    print(f\"Training {modelname}...\")\n",
        "# for _, model in enumerate(modellist):\n",
        "    model.to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "    # try to integrate into wandb instead of storing this so we can have a pretty dashboard?\n",
        "    history = {\n",
        "        \"train_loss\": [],\n",
        "        \"val_loss\": [],\n",
        "        \"train_acc\": [],\n",
        "        \"val_acc\": [],\n",
        "        \"val_auc\": []\n",
        "    }\n",
        "\n",
        "    best_auc = -np.inf\n",
        "    best_state = None\n",
        "    bad_epochs = 0\n",
        "\n",
        "    print(\"\\nStarting training...\\n\")\n",
        "    for epoch in tqdm(range(1, EPOCHS + 1)):\n",
        "        # TODO: Train for one epoch\n",
        "        tr_loss, tr_acc, _, _, _ = run_epoch(train_loader, model, criterion, optimizer=optimizer, train=True, device=device)\n",
        "\n",
        "        # TODO: Validate\n",
        "        va_loss, va_acc, va_sens, va_spec, va_auc = run_epoch(val_loader, model, criterion, optimizer=None, train=False,device=device)\n",
        "\n",
        "        # TODO: Store metrics\n",
        "        history[\"train_loss\"].append(tr_loss)\n",
        "        history[\"val_loss\"].append(va_loss)\n",
        "        history[\"train_acc\"].append(tr_acc)\n",
        "        history[\"val_acc\"].append(va_acc)\n",
        "        history[\"val_auc\"].append(va_auc)\n",
        "\n",
        "        print(f\"Epoch {epoch:02d}: \"\n",
        "            f\"train_loss={tr_loss:.4f} \"\n",
        "            f\"val_loss={va_loss:.4f} \"\n",
        "            f\"val_acc={va_acc:.3f} \"\n",
        "            f\"val_auc={va_auc:.3f}\")\n",
        "\n",
        "        # TODO: Early stopping logic\n",
        "        if va_auc > best_auc + 1e-4:\n",
        "            # TODO: Update the best AUC\n",
        "            best_auc = va_auc\n",
        "            best_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n",
        "            bad_epochs = 0\n",
        "        else:\n",
        "            bad_epochs += 1\n",
        "            if bad_epochs >= PATIENCE:\n",
        "                print(f\"\\nEarly stopping at epoch {epoch}\")\n",
        "                break\n",
        "\n",
        "    # Restore best model\n",
        "    if best_state is not None:\n",
        "        model.load_state_dict(best_state)\n",
        "        print(f\"\\nRestored best model (val_auc={best_auc:.4f})\")\n",
        "\n",
        "    historylist.append(history)\n",
        "    stopepochs.append(epoch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1e442430",
      "metadata": {
        "id": "1e442430"
      },
      "outputs": [],
      "source": [
        "# finally, evaluate on test set\n",
        "\n",
        "# for _, model in tqdm(enumerate(modellist)):\n",
        "for modelname, model in modeldict.items():\n",
        "    print(f\"\\nEvaluating {modelname}...\")\n",
        "    model.to(device)\n",
        "    _, va_acc, va_sens, va_spec, va_auc = run_epoch(test_loader, model, criterion, train=False, device=device)\n",
        "    print(f\"Final Validation Performance:\")\n",
        "    print(f\"  AUC:         {va_auc:.4f}\")\n",
        "    print(f\"  Accuracy:    {va_acc:.4f}\")\n",
        "    print(f\"  Sensitivity: {va_sens:.4f}\")\n",
        "    print(f\"  Specificity: {va_spec:.4f}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}